# Эффективное кеширование. От теории к практике

13 мин

66K

[Блог компании Surfingbird](https://habr.com/ru/companies/surfingbird/articles/)[Perl*](https://habr.com/ru/hubs/perl/)[Java*](https://habr.com/ru/hubs/java/)[Алгоритмы*](https://habr.com/ru/hubs/algorithms/)[Разработка под Android*](https://habr.com/ru/hubs/android_dev/)

![image](https://habrastorage.org/r/w1560/getpro/habr/post_images/7e7/6f9/fa1/7e76f9fa16c5fb09cf27fccd98e62ef5.jpg)  
  
Как правило, статьи о кешировании начинаются за здравие, а заканчиваются [LRU](https://habrahabr.ru/post/136758/) кешем. Попробуем переломить эту тенденцию? Начнем с того, чем LRU плох, а закончим за здравие. Я надеюсь.  
  
Вне зависимости от того, строите ли вы [хайлоад сервис для миллионов посетителей](https://relap.io/) или проектируете мобильное приложение, пишите операционную систему или СУБД — ключевое звено, влияющее на конечную стоимость системы и на отзывчивость интерфейса/сервиса — это кеш.  
  
Спрашивая на собеседованиях какие алгоритмы кеширования вы знаете — как правило слышишь в ответ, ммм… LRU Cache… Зато если спросить про алгоритмы сортировки, вероятность услышать что-то помимо «Пузырек» — значительно выше. Человек готов потратить несколько дней на поиск оптимальной библиотеки ресайза изображений или веб фреймворка, не понимая, что реализовав эффективный кеш, он может взять в принципе любую библиотеку со схожими характеристиками, так как кеш — минимизирует обращения к ней, сгладив разницу в быстродействии.  
  
Для [Relap.io](https://relap.io/), как для хайлоад сервиса, кеширование особенно важно. Например, вчера мы показали рекомендации на различных сайтах 789301033 раз. Поэтому у нас густо обмазано кешем все: рекомендации, картинки, реклама и так далее.  
  

#### **Не все кеши одинаково полезны**

  
Хороший пример LRU Cache.  
  
На конкурсы алгоритмов его обычно не берут. Никто не хочет иметь ничего общего с неудачником. Сложно придумать более неэффективный алгоритм. Единственный алгоритм, у которого LRU Cache выигрывает по эффективности — это, наверно, просто очередь, например, FIFO. Тем не менее, LRU встроен везде и всюду как дефолтный и, к сожалению, часто единственный алгоритм, так как он прост в реализации.  
  
Вам хотелось бы пользоваться сайтом, приложением или операционной системой, которая тормозит, неэффективна и жрет ресурсы как не в себя, но зато она написана на простом в реализации языке, например, условном бейсике? Если нет — добро пожаловать под кат.  
  
Я люблю правило Парето. На стат значимой выборке его можно применять абсолютно ко всему.  
  
Давайте попробуем:  

- 20% усилий приносят 80% результата,
- 20% товаров приносят 80% прибыли,
- на 20% урлов приходится 80% просмотров,
- 20% кода реализуют 80% функционала.

  
  
Это довольно интересная закономерность справедливая для больших массивов данных. Казалось бы, причем тут Парето?  
  

> <Лирическое отступление>  
> Несколько лет назад мы писали приложение под андроид для Surfingbird. Мы перешли на RX Java. Асинхронизировали все что можно. Сгладили все переходы анимацией, тем не менее осталась одна нерешенная проблема, это постоянные перезагрузки картинок. И ваше приложение буквально кишит картинками, и они постоянно ротируются меняются и вам не хватает памяти для их размещения.  
>   
> Признаюсь, я поначалу думал что все дело в имаджлоадере. Достаточно выбрать эффективный и вуаля. Я пересмотрел все. Пикассо, Фейсбуковский fresco, UIL не помню уже все названия. Но проблема оставалась. Картинки грузились где то чуть быстрее, где то чуть плавнее, но они грузились. Тогда я сел, и написал [свой](https://habrahabr.ru/post/262189/). Простой. Чистый. Легкий. И это не помогло. Глупые имаджлоадеры продолжали постоянно теребить картинки нервируя пользователя и никак не могли отделить зерна от плевел. Тогда я вспомнил о правиле Парето.  
> </Лирическое отступление>

  
  
Если предположить, что 20% картинок — показываются 80% раз — все встает на свои места. Единственное что осталось понять — какие именно картинки надо хранить.  
  

#### **Как работает LRU cache?**

  
  
Давайте рассмотрим сферическое приложение в вакууме. Пусть это будет мессенджер, его проще всего представить.  
  
**скриншот_из_телеграмм.jpg**  
  
Если внимательно посмотреть на скриншот, то можно увидеть, что сообщения пользователей сопровождаются аватарками, а в теле сообщений — встречаются картинки. Перед вами стоит задача — сделать максимально плавный интерфейс. Давайте еще раз взглянем на скриншот выше. Мы видим 2 повторяющиеся автарки в диалоге, и затем юзер 1 прислал большую картинку.  
  

- Пришла аватарка 1 — 100 на 100 пикселей, мы записали в кеш 100*100*4 байт.
- Пришла аватарка 2 — 100 на 100 пикселей, мы записали в кеш 100*100*4 байт.
- Пришла аватарка 1 — мы подняли ее в очереди наверх.

  
  
Пока все идет неплохо.  
  
Пришла картинка 1024 на 768 пикселей, мы записали в кеш 1024*768*4 байт — и БАМ! Наши прекрасные аватарки выбило напрочь из кеша. Теперь там торжественно валяется картинка, которую нужно было показать один раз и не нужно было кешировать.  
  

#### **Как победить?**

  
  
Если посмотреть, например, на библиотеку AQuery, то разработчик предлагает разделить кеш на несколько кучек. Отдельная кучка для маленьких аватарок, отдельная кучка для больших картинок. Уже хлеб кстати, но это решение не универсально, требует программирования и внимания, а хочется всего и сразу. Так как все интересное уже было придумано до нас — самое время взглянуть на то, какие еще существуют алгоритмы кеширования.  
  
[Статья в вики](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC%D1%8B_%D0%BA%D1%8D%D1%88%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F)  
  
Простите, что я тут чуть чуть сжухлю, и опишу очень коротко прописные истины.  
  
**LRU** — не использованный дольше всех вылетает из кеша.  
**MRU** — последний использованный вылетает из кеша (специфичный кейс, бережем старье).  
**LFU** — реже всего использованный вылетает из кеша.  
  
Это база. Вас может испугать что затраты на вычисления растут с ростом сложности алгоритмов, но не критично. Попробуйте сравнить время лукапов по ключам в памяти со временем рендеринга картинки 1024 на 768. А именно это произойдет если алгоритм «промахнулся».  
  
**SNLRU** (сегментированный LRU) — заводим несколько «коробочек» с LRU. Сперва кладем в первую коробочку, при повтороном запросе перекладываем во вторую из второй — в третью.  
  
Если назвать коробочки — будет понятнее:  

- Cold — первая коробочка,
- Warm — вторая,
- Hot — третья.

  
  
Это уже неплохой алгоритм, он используется в недрах freebsd, если не ошибаюсь. По крайней мере я сталкивался с ним в данном контексте.  
  
**Mid point LRU** — сегментированный LRU в котором всего две коробочки.  
  
**MQ** — сегментированный LRU в котором запоминаем. Запоминается позиция с которой элемент вылетел — и при повторном запросе — возвращается туда, где был, если не вылетел из очереди запомненных позиций. По сути кеш быстрее прогревается в случае циклической ротации элементов (какашечки могут стать популярными). Выглядит как довольно странный юзкейс.  
  
**ARC, GCLOCK** — и прочие более сложные алгоритмы придется на время вынести за скобки. Не то чтобы они плохие или неинтересные, тот же ARC используется (точнее, наверное, использовался, судя по данной преисполненной боли статье: [www.varlena.com/GeneralBits/96.php](http://www.varlena.com/GeneralBits/96.php)) в postgreSQL. Не удержусь от небольшой цитаты:  
  

> Database systems often use LRU algorithms but many are switching to other algorithms to better handle a variety of behaviors not handled well by LRU. For example, one one-time very large sequential scan might flood the cache with pages that are not expected to be used again any time soon. The cache then is not helpful until it is re-populated with more commonly used pages.

  
  
**2Q** — или две очереди, примечателен тем, что сохраняя простоту реализации, он прекрасно адаптируется. Кеш разделяется на три части, как в сегментированном LRU, но с более сложной стратегией:  
  

- Первая часть In — FIFO входящий кеш в который помещаются новые элементы.
- Вторая часть Out — FIFO исходящий кеш, в который перемещаются элементы, вытесненные из коробочки In.
- Третья часть Hot LRU кеш для элементов, запрошенных из Out.

  
  
Стратегия вытеснения из кеша:  
  

- элементы запрошенные из In никуда не двигаются. Вытесненные из In элементы — перемещаются в Out.
- элементы запрошенные из Out — попадают в рай, в коробочку Main. Вытесненные же из Out (не использованные) — попадают сразу в ад (null).

  
  
Ссылка на каноническое [описание](http://www.vldb.org/conf/1994/P439.PDF).  
  
Во первых — это красиво. Коробочку Main — делаем, например, 20% (помните о Парето?) именно тут скопятся наши аватарки. А вот Out — надо сделать побольше, процентов 60. Так как это «отстойник».  
  
В чем прелесть In — новые элементы спокойно спускаются по FIFO трубе из In в Out, не подпрыгивая и никуда не перемещаясь по мере запросов. А вот если опять запросили (например пользователь подскролил вверх) и, картинка успела перейти из In в Out — вот она картинка победительница. Кеш на уровне архитектуры корректирует некие типичные корреляции, присутствующие в обычной жизни. И после внедрения исчезли постоянные перезагрузки в условиях ограниченного размера памяти. Парето сработал. Но мы еще не раз вернемся к Парето.  
  
Во первых, перейдем к нюансам. Когда читаешь про три коробочки, есть невольный соблазн прямо так тупо и сделать три связанных списка и гонять по ним элементы. Но это неэффективный путь, и как-то не по-джедайски. На самом деле, нам нужно знать только, в какой коробочке лежит ключ, а сами значения могут валяться в это время в некой безобразной куче. Перейдем же скорее к программированию.  
  

**Реализация на java, бам!**

  
  
Обратите внимание на контейнеры:  

```
    /** Primary container */    private final HashMap<K,V> map;    /** Sets for 2Q algorithm */    private final LinkedHashSet<K> mapIn, mapOut, mapHot;
```

  
  
Управление «кучками» реализовано на супербыстрых и экономичных по памяти LinkedHashSet, нам не важно значение, важно лишь в какой «кучке» какой ключ находится в данный момент. Это ключ к быстродействию.  
  
Больше практики. Допустим мы хотим прикрутить его к имадж лоадеру — пул реквест к пикассо: [github.com/square/picasso/pull/1134](https://github.com/square/picasso/pull/1134)  
Но вообще это не обязательно. Нормальные либы — позволяют подключить произвольный алгоритм кеширования — достаточно скопипастить [класс](https://github.com/recoilme/2qcache/blob/master/lib/RLP/TwoQueuesCache.java) и переопределить кеш (glide вроде умел, picasso, начиная с какой то версии)  
  
Я уже не помню точных цифр по хитрейту в своем случае. Помню только что у LRU — хитрейт был более 70% но менее 80. У 2Q — чуть более 80%. Но чудо произошло. Потому что все, что нам надо — это закешировать 20% инфы, которая составит 80% трафика. Чудо еще кстати состояло в том, что по скорости 2Q был быстрее LRU.  
  
У нас в [Relap.io](http://relap.io/), несколько реализаций кешей, например моя — [github.com/recoilme/2qcache](https://github.com/recoilme/2qcache) (вообще я не перл программист, это моя первая и надеюсь единственная программа на этом языке, единственный ее плюс — она простая).  
  
Поэтому рекомендую посмотреть на реализацию 2Q на перле от нашего ведущего разработчика:  
  
Реализация на перле, бам: [github.com/grinya007/2q](https://github.com/grinya007/2q)  
  
Итак, не важно, что вы пишете: сайт, хайлоад-сервис, мобильное приложение или операционную систему, реализовав единожды умный алгоритм кеширования, вы можете использовать его повсеместно, экономя ресурсы и нервы пользователя.

Теги: 

- [2Q Cache](https://habr.com/ru/search/?target_type=posts&order=relevance&q=%5B2Q%20Cache%5D)
- [LRU](https://habr.com/ru/search/?target_type=posts&order=relevance&q=%5BLRU%5D)
- [MRU](https://habr.com/ru/search/?target_type=posts&order=relevance&q=%5BMRU%5D)
- [LFU](https://habr.com/ru/search/?target_type=posts&order=relevance&q=%5BLFU%5D)
- [SNLRU](https://habr.com/ru/search/?target_type=posts&order=relevance&q=%5BSNLRU%5D)
- [MQ](https://habr.com/ru/search/?target_type=posts&order=relevance&q=%5BMQ%5D)

Хабы: 

- [Блог компании Surfingbird](https://habr.com/ru/companies/surfingbird/articles/)
- [Perl](https://habr.com/ru/hubs/perl/)
- [Java](https://habr.com/ru/hubs/java/)
- [Алгоритмы](https://habr.com/ru/hubs/algorithms/)
- [Разработка под Android](https://habr.com/ru/hubs/android_dev/)